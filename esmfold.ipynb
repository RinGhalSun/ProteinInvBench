{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengsun/miniconda3/envs/se3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import esm\n",
    "import time\n",
    "import csv\n",
    "import torch\n",
    "from data import utils as du\n",
    "from typing import Dict\n",
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_folding(sequence, save_path, target_gpu_index):\n",
    "    \"\"\"Run ESMFold on sequence.\"\"\"\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device_index = target_gpu_index\n",
    "        device_name = f\"cuda:{device_index}\"\n",
    "        device = torch.device(device_name)\n",
    "        model = esm.pretrained.esmfold_v1()\n",
    "        model = model.to(device)\n",
    "        model = model.eval()    \n",
    "    \n",
    "    \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        output = model.infer_pdb(sequence)\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(output)\n",
    "    import biotite.structure.io as bsio\n",
    "    struct = bsio.load_structure(save_path, extra_fields=[\"b_factor\"])\n",
    "    plddt = struct.b_factor.mean()\n",
    "    return output, plddt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_esm_all(sample_sequences, decoy_pdb_dir, model_dataset):\n",
    "    total_samples = len(sample_sequences)\n",
    "    start_time = time.time()\n",
    "\n",
    "    os.makedirs(decoy_pdb_dir, exist_ok=True)\n",
    "    plddt_csv_path = os.path.join(decoy_pdb_dir, model_dataset, \"plddt_values.csv\")\n",
    "\n",
    "    write_header = not os.path.exists(plddt_csv_path)\n",
    "\n",
    "    # 使用 'a' 模式打开 CSV 文件并实时写入\n",
    "    with open(plddt_csv_path, \"a\", newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        if write_header:\n",
    "            csv_writer.writerow([\"Sample\", \"PLDDT\"])\n",
    "\n",
    "        for idx, (sample, sequence) in enumerate(sample_sequences.items(), 1):\n",
    "            esmf_dir = os.path.join(decoy_pdb_dir, model_dataset)\n",
    "            os.makedirs(esmf_dir, exist_ok=True)\n",
    "            esmf_sample_path = os.path.join(esmf_dir, f'{sample}.pdb')\n",
    "\n",
    "            # 检查文件是否已存在，如果存在则跳过\n",
    "            if os.path.exists(esmf_sample_path):\n",
    "                print(f\"File {esmf_sample_path} already exists. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # 运行折叠函数，获取输出和PLDDT值\n",
    "            output, plddt_value = run_folding(sequence, esmf_sample_path, 0)\n",
    "            print(plddt_value)\n",
    "\n",
    "            # 将结果实时写入 CSV 文件\n",
    "            csv_writer.writerow([sample, plddt_value])\n",
    "\n",
    "            # 计算并打印进度\n",
    "            elapsed_time = time.time() - start_time\n",
    "            progress_percentage = (idx / total_samples) * 100\n",
    "            print(f\"Progress: {progress_percentage:.2f}% | Elapsed Time: {elapsed_time:.2f}s | ESM results saved for {sample} in {esmf_sample_path}\")\n",
    "\n",
    "    print(f\"ESM calculations for all samples completed and saved to CSV at {plddt_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_predicted_sequences(fasta_file_path):\n",
    "    predicted_sequences = {}\n",
    "\n",
    "    for record in SeqIO.parse(fasta_file_path, \"fasta\"):\n",
    "        header = record.description\n",
    "        if \"Predicted sequence\" in header:\n",
    "            pdb_id = header.split()[0].split('.')[0]\n",
    "            sequence = str(record.seq)\n",
    "            predicted_sequences[pdb_id] = sequence\n",
    "\n",
    "    return predicted_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATH4.2 PiFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file_path = \"/home/zhengsun/code/protein/ProteinInvBench/results/fasta_files/CATH4.2_PiFold.fasta\"\n",
    "sample_sequences = read_predicted_sequences(fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb/cath42pifold/1a1x.pdb already exists. Skipping...\n",
      "File /home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb/cath42pifold/1a2p.pdb already exists. Skipping...\n",
      "File /home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb/cath42pifold/1a32.pdb already exists. Skipping...\n",
      "62.47464489795919\n",
      "Progress: 0.37% | Elapsed Time: 28.23s | ESM results saved for 1a73 in /home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb/cath42pifold/1a73.pdb\n",
      "88.64814387699066\n",
      "Progress: 0.46% | Elapsed Time: 56.94s | ESM results saved for 1a8l in /home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb/cath42pifold/1a8l.pdb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m decoy_pdb_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_esm_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoy_pdb_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcath42pifold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mrun_esm_all\u001b[0;34m(sample_sequences, decoy_pdb_dir, model_dataset)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mesmf_sample_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists. Skipping...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m output, plddt_value \u001b[38;5;241m=\u001b[39m \u001b[43mrun_folding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mesmf_sample_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(plddt_value)\n\u001b[1;32m     25\u001b[0m csv_writer\u001b[38;5;241m.\u001b[39mwriterow([sample, plddt_value])\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mrun_folding\u001b[0;34m(sequence, save_path, target_gpu_index)\u001b[0m\n\u001b[1;32m      7\u001b[0m device_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device_name)\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mesm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mesmfold_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()    \n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/pretrained.py:420\u001b[0m, in \u001b[0;36mesmfold_v1\u001b[0;34m()\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03mESMFold v1 model using 3B ESM-2, 48 folding blocks.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03mESMFold provides fast high accuracy atomic level structure prediction\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03mprotein sequence.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mesm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mesmfold\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mesm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mesmfold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mesmfold_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/esmfold/v1/pretrained.py:54\u001b[0m, in \u001b[0;36mesmfold_v1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mesmfold_v1\u001b[39m():\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    ESMFold v1 model using 3B ESM-2, 48 folding blocks.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    ESMFold provides fast high accuracy atomic level structure prediction\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    protein sequence.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mesmfold_3B_v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/esmfold/v1/pretrained.py:18\u001b[0m, in \u001b[0;36m_load_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m cfg \u001b[38;5;241m=\u001b[39m model_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m model_state \u001b[38;5;241m=\u001b[39m model_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mESMFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mesmfold_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m expected_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(model\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     21\u001b[0m found_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(model_state\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/esmfold/v1/esmfold.py:43\u001b[0m, in \u001b[0;36mESMFold.__init__\u001b[0;34m(self, esmfold_config, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistogram_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mesm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mesm_dict \u001b[38;5;241m=\u001b[39m \u001b[43mesm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mesm2_t36_3B_UR50D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mesm\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mesm\u001b[38;5;241m.\u001b[39mhalf()\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/pretrained.py:387\u001b[0m, in \u001b[0;36mesm2_t36_3B_UR50D\u001b[0;34m()\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mesm2_t36_3B_UR50D\u001b[39m():\n\u001b[1;32m    383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"36 layer ESM-2 model with 3B params, trained on UniRef50.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Returns a tuple of (Model, Alphabet).\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_and_alphabet_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mesm2_t36_3B_UR50D\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/pretrained.py:63\u001b[0m, in \u001b[0;36mload_model_and_alphabet_hub\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_and_alphabet_hub\u001b[39m(model_name):\n\u001b[0;32m---> 63\u001b[0m     model_data, regression_data \u001b[38;5;241m=\u001b[39m \u001b[43m_download_model_and_regression_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_and_alphabet_core(model_name, model_data, regression_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/pretrained.py:54\u001b[0m, in \u001b[0;36m_download_model_and_regression_data\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_model_and_regression_data\u001b[39m(model_name):\n\u001b[1;32m     53\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://dl.fbaipublicfiles.com/fair-esm/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m     model_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_hub_workaround\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _has_regression_weights(model_name):\n\u001b[1;32m     56\u001b[0m         regression_data \u001b[38;5;241m=\u001b[39m load_regression_hub(model_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/esm/pretrained.py:33\u001b[0m, in \u001b[0;36mload_hub_workaround\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_hub_workaround\u001b[39m(url):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# Pytorch version issue - see https://github.com/pytorch/pytorch/issues/43106\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         fn \u001b[38;5;241m=\u001b[39m Path(url)\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/torch/hub.py:735\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n\u001b[0;32m--> 735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/torch/serialization.py:1101\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1100\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/miniconda3/envs/se3/lib/python3.9/site-packages/torch/serialization.py:1079\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1077\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1079\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39muntyped()\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m   1083\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1084\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoy_pdb_dir = \"/home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb\"\n",
    "run_esm_all(sample_sequences, decoy_pdb_dir, 'cath42pifold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATH4.2 ProteinMPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file_path = \"/home/zhengsun/code/protein/ProteinInvBench/results/fasta_files/CATH4.2_ProteinMPNN.fasta\"\n",
    "sample_sequences = read_predicted_sequences(fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoy_pdb_dir = \"/home/zhengsun/code/protein/ProteinInvBench/results/esm_fold_pdb\"\n",
    "run_esm_all(sample_sequences, decoy_pdb_dir, 'cath42mpnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
